# -*- coding: utf-8 -*-
"""PRINCIPAL COMPONENT ANALYSIS.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jHbFboWdhtMuKdRmVgbxgzX3rHw9AzIg
"""

import numpy as np
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA

np.random.seed(42)
sample_count = 100
feature_one = np.random.randn(sample_count)
feature_two = 2.5 * feature_one + np.random.randn(sample_count) * 0.5
data_matrix = np.column_stack((feature_one, feature_two))

pca_transformer = PCA(n_components=2)
pca_transformer.fit(data_matrix)
transformed_matrix = pca_transformer.transform(data_matrix)

eigenvectors = pca_transformer.components_
mean_vector = pca_transformer.mean_

plt.figure(figsize=(7, 5), facecolor='white')
plt.scatter(data_matrix[:, 0], data_matrix[:, 1], alpha=0.6, label="Original Data")

for vec, variance in zip(eigenvectors, pca_transformer.explained_variance_):
    direction = vec * np.sqrt(variance) * 2
    plt.arrow(mean_vector[0], mean_vector[1], direction[0], direction[1],
              color='red', width=0.05, head_width=0.15, label="Principal Components")

plt.xlabel("Feature A")
plt.ylabel("Feature B")
plt.title("PCA Visualization")
plt.legend()
plt.gca().set_facecolor('white')

plt.show()

print("Explained Variance Proportions:", pca_transformer.explained_variance_ratio_)
print("Eigenvectors:\n", pca_transformer.components_)